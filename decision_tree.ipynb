{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9aeb763",
   "metadata": {},
   "source": [
    "## Using the titanic data, in your classification-exercises repository, create a notebook, decision_tree.ipynb where you will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c14c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydataset\n",
    "from env import get_db_url\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from prepare import prep_titanic\n",
    "from prepare import titanic_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import graphviz\n",
    "#from graphviz import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9a0885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>baseline_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex  sibsp  parch     fare embarked  \\\n",
       "0             0         0       3    male      1      0   7.2500        S   \n",
       "1             1         1       1  female      1      0  71.2833        C   \n",
       "2             2         1       3  female      0      0   7.9250        S   \n",
       "3             3         1       1  female      1      0  53.1000        S   \n",
       "4             4         0       3    male      0      0   8.0500        S   \n",
       "\n",
       "   alone  sex_male  embarked_Q  embarked_S  baseline_prediction  \n",
       "0      0         1           0           1                    0  \n",
       "1      0         0           0           0                    0  \n",
       "2      1         0           0           1                    0  \n",
       "3      0         0           0           1                    0  \n",
       "4      1         1           0           1                    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prep_titanic()\n",
    "df['baseline_prediction'] = 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d74a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, train, validate, test = titanic_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b2623",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid #000000;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eaa65e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((534, 13), (178, 13), (179, 13))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect size\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9bbcc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 534 entries, 455 to 496\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   passenger_id         534 non-null    int64  \n",
      " 1   survived             534 non-null    int64  \n",
      " 2   pclass               534 non-null    int64  \n",
      " 3   sex                  534 non-null    object \n",
      " 4   sibsp                534 non-null    int64  \n",
      " 5   parch                534 non-null    int64  \n",
      " 6   fare                 534 non-null    float64\n",
      " 7   embarked             534 non-null    object \n",
      " 8   alone                534 non-null    int64  \n",
      " 9   sex_male             534 non-null    uint8  \n",
      " 10  embarked_Q           534 non-null    uint8  \n",
      " 11  embarked_S           534 non-null    uint8  \n",
      " 12  baseline_prediction  534 non-null    int64  \n",
      "dtypes: float64(1), int64(7), object(2), uint8(3)\n",
      "memory usage: 47.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 178 entries, 176 to 837\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   passenger_id         178 non-null    int64  \n",
      " 1   survived             178 non-null    int64  \n",
      " 2   pclass               178 non-null    int64  \n",
      " 3   sex                  178 non-null    object \n",
      " 4   sibsp                178 non-null    int64  \n",
      " 5   parch                178 non-null    int64  \n",
      " 6   fare                 178 non-null    float64\n",
      " 7   embarked             178 non-null    object \n",
      " 8   alone                178 non-null    int64  \n",
      " 9   sex_male             178 non-null    uint8  \n",
      " 10  embarked_Q           178 non-null    uint8  \n",
      " 11  embarked_S           178 non-null    uint8  \n",
      " 12  baseline_prediction  178 non-null    int64  \n",
      "dtypes: float64(1), int64(7), object(2), uint8(3)\n",
      "memory usage: 15.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 561 to 53\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   passenger_id         179 non-null    int64  \n",
      " 1   survived             179 non-null    int64  \n",
      " 2   pclass               179 non-null    int64  \n",
      " 3   sex                  179 non-null    object \n",
      " 4   sibsp                179 non-null    int64  \n",
      " 5   parch                179 non-null    int64  \n",
      " 6   fare                 179 non-null    float64\n",
      " 7   embarked             179 non-null    object \n",
      " 8   alone                179 non-null    int64  \n",
      " 9   sex_male             179 non-null    uint8  \n",
      " 10  embarked_Q           179 non-null    uint8  \n",
      " 11  embarked_S           179 non-null    uint8  \n",
      " 12  baseline_prediction  179 non-null    int64  \n",
      "dtypes: float64(1), int64(7), object(2), uint8(3)\n",
      "memory usage: 15.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect\n",
    "train.info(), validate.info(), test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639bed78",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f11138e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>baseline_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex  sibsp  parch     fare embarked  \\\n",
       "0             0         0       3    male      1      0   7.2500        S   \n",
       "1             1         1       1  female      1      0  71.2833        C   \n",
       "2             2         1       3  female      0      0   7.9250        S   \n",
       "3             3         1       1  female      1      0  53.1000        S   \n",
       "4             4         0       3    male      0      0   8.0500        S   \n",
       "\n",
       "   alone  sex_male  embarked_Q  embarked_S  baseline_prediction  \n",
       "0      0         1           0           1                    0  \n",
       "1      0         0           0           0                    0  \n",
       "2      1         0           0           1                    0  \n",
       "3      0         0           0           1                    0  \n",
       "4      1         1           0           1                    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e5c7d1",
   "metadata": {},
   "source": [
    "### Chekcing to the count for survived passengers. \n",
    "* The value 0 means False and 1 means True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "879d4822",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc6e5690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>baseline_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass   sex  sibsp  parch  fare embarked  alone  \\\n",
       "0             0         0       3  male      1      0  7.25        S      0   \n",
       "\n",
       "   sex_male  embarked_Q  embarked_S  baseline_prediction  \n",
       "0         1           0           1                    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271a946",
   "metadata": {},
   "source": [
    "## The baseline accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6bd11a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161616161616161"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the baseline accuracy\n",
    "baseline_accuracy = (df.survived == df.baseline_prediction).mean()\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052acc32",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid #000000;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf801f48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passenger_id', 'survived', 'pclass', 'sex', 'sibsp', 'parch', 'fare',\n",
       "       'embarked', 'alone', 'sex_male', 'embarked_Q', 'embarked_S',\n",
       "       'baseline_prediction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3952672d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pclass', 'sex', 'sibsp', 'parch', 'fare', 'alone', 'sex_male')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'pclass', 'sex', 'sibsp', 'parch', 'fare', 'alone', 'sex_male', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0839966b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id             int64\n",
       "survived                 int64\n",
       "pclass                   int64\n",
       "sex                     object\n",
       "sibsp                    int64\n",
       "parch                    int64\n",
       "fare                   float64\n",
       "embarked                object\n",
       "alone                    int64\n",
       "sex_male                 uint8\n",
       "embarked_Q               uint8\n",
       "embarked_S               uint8\n",
       "baseline_prediction      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9223918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fare'] = df['fare'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c522c3cc",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid #000000;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fce84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X & y version of train/validate/test\n",
    "# where X contains the features we want to use and y is a series with just the target variable\n",
    "\n",
    "X_train = train.drop(columns=['passenger_id', 'survived', 'sex', 'embarked', 'embarked_Q', \n",
    "        'embarked_S', 'baseline_prediction'])\n",
    "y_train = train.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb4d3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate.drop(columns=['passenger_id', 'survived', 'sex', 'embarked', 'embarked_Q', \n",
    "        'embarked_S', 'baseline_prediction'])\n",
    "y_validate = validate.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0daac119",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(columns=['passenger_id', 'survived', 'sex', 'embarked', 'embarked_Q', \n",
    "        'embarked_S', 'baseline_prediction'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9059e2",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid #000000;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea0a9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "['passenger_id', 'survived', 'pclass', 'sex', 'sibsp', 'parch', 'fare', 'embarked', 'alone', 'sex_male', 'embarked_Q', 'embarked_S', 'baseline_prediction'] \n",
      "_____________________________________________\n",
      "X_train:\n",
      "['pclass', 'sibsp', 'parch', 'fare', 'alone', 'sex_male']\n",
      "_____________________________________________\n",
      "X_validate:\n",
      "['pclass', 'sibsp', 'parch', 'fare', 'alone', 'sex_male']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Compare df columns\n",
    "\n",
    "print(f\"\"\"train:\n",
    "{train.columns.to_list()} \n",
    "_____________________________________________\n",
    "X_train:\n",
    "{X_train.columns.to_list()}\n",
    "_____________________________________________\n",
    "X_validate:\n",
    "{X_validate.columns.to_list()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714f8922",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d07f342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9359dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c0e55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4c3bc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction on train obeservations\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c5ea596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.905     , 0.095     ],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.69105691, 0.30894309],\n",
       "       [0.69105691, 0.30894309],\n",
       "       [0.905     , 0.095     ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#estimates probabilty\n",
    "\n",
    "y_proba = clf.predict_proba(X_train)\n",
    "y_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "106f62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "#compute the accuracy\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9600175d",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4433e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d219bffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8183520599250936"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the accuracy score of train set\n",
    "train_score = clf.score(X_train, y_train)\n",
    "train_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f43008af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>295</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>63</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred 0  Pred 1\n",
       "Actual 0     295      34\n",
       "Actual 1      63     142"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], \n",
    "             columns=['Pred 0', 'Pred 1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b41fbb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    329\n",
       "1    205\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target value count\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c9eddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       329\n",
      "           1       0.81      0.69      0.75       205\n",
      "\n",
      "    accuracy                           0.82       534\n",
      "   macro avg       0.82      0.79      0.80       534\n",
      "weighted avg       0.82      0.82      0.82       534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c52bf5f",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f77c1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    " def print_cm_metrics(cm):    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "\n",
    "    true_positive_rate = tp/(tp + fn)\n",
    "    false_positive_rate = fp/(fp + tn)\n",
    "    true_negative_rate = tn/(tn + fp)\n",
    "    false_negative_rate = fn/(fn + tp)\n",
    "\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "    support_pos = tp + fn\n",
    "    support_neg = fp + tn\n",
    "\n",
    "    dict = {\n",
    "        'metric' : ['accuracy'\n",
    "                    ,'true_positive_rate'\n",
    "                    ,'false_positive_rate'\n",
    "                    ,'true_negative_rate'\n",
    "                    ,'false_negative_rate'\n",
    "                    ,'precision'\n",
    "                    ,'recall'\n",
    "                    ,'f1_score'\n",
    "                    ,'support_pos'\n",
    "                    ,'support_neg']\n",
    "        ,'score' : [accuracy\n",
    "                    ,true_positive_rate\n",
    "                    ,false_positive_rate\n",
    "                    ,true_negative_rate\n",
    "                    ,false_negative_rate\n",
    "                    ,precision\n",
    "                    ,recall\n",
    "                    ,f1_score\n",
    "                    ,support_pos\n",
    "                    ,support_neg]\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da18d222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.818352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true_positive_rate</td>\n",
       "      <td>0.692683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>false_positive_rate</td>\n",
       "      <td>0.103343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true_negative_rate</td>\n",
       "      <td>0.896657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false_negative_rate</td>\n",
       "      <td>0.307317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.806818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.692683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.745407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>support_pos</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>support_neg</td>\n",
       "      <td>329.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metric       score\n",
       "0             accuracy    0.818352\n",
       "1   true_positive_rate    0.692683\n",
       "2  false_positive_rate    0.103343\n",
       "3   true_negative_rate    0.896657\n",
       "4  false_negative_rate    0.307317\n",
       "5            precision    0.806818\n",
       "6               recall    0.692683\n",
       "7             f1_score    0.745407\n",
       "8          support_pos  205.000000\n",
       "9          support_neg  329.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_cm_metrics(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cd3f1d",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2ec8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(k, X, y):\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth=k, random_state=123)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    \n",
    "    y_proba = clf.predict_proba(X)\n",
    "    \n",
    "    \n",
    "    return y_pred, y_proba, k, clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0d06e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_metrics(X, y, y_pred):\n",
    "    score = clf.score(X, y)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    \n",
    "    report = classification_report(y, y_pred)\n",
    "    \n",
    "    return score, cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a74fb30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.818352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true_positive_rate</td>\n",
       "      <td>0.692683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>false_positive_rate</td>\n",
       "      <td>0.103343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true_negative_rate</td>\n",
       "      <td>0.896657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false_negative_rate</td>\n",
       "      <td>0.307317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.806818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.692683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.745407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>support_pos</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>support_neg</td>\n",
       "      <td>329.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metric       score\n",
       "0             accuracy    0.818352\n",
       "1   true_positive_rate    0.692683\n",
       "2  false_positive_rate    0.103343\n",
       "3   true_negative_rate    0.896657\n",
       "4  false_negative_rate    0.307317\n",
       "5            precision    0.806818\n",
       "6               recall    0.692683\n",
       "7             f1_score    0.745407\n",
       "8          support_pos  205.000000\n",
       "9          support_neg  329.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_cm_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38f275da",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list1 = decision_metrics(X_train, y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c169891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score for the model is:\n",
      "0.8183520599250936\n",
      "--------\n",
      "Confusion Matrix:\n",
      "[[295  34]\n",
      " [ 63 142]]\n",
      "--------\n",
      "Confusion Matrix DataFrame:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       329\n",
      "           1       0.81      0.69      0.75       205\n",
      "\n",
      "    accuracy                           0.82       534\n",
      "   macro avg       0.82      0.79      0.80       534\n",
      "weighted avg       0.82      0.82      0.82       534\n",
      "\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "list = ['The train score for the model is:', 'Confusion Matrix:', 'Confusion Matrix DataFrame:', 'Classification Report:']\n",
    "\n",
    "for i, metric in enumerate(metric_list1): # to add number to a tuple ex.: (o, seq[0]), (1, seq[1])\n",
    "    if i == 2:\n",
    "        print(list[2])\n",
    "        print(metric)\n",
    "        print('--------')\n",
    "    else:\n",
    "        print(list[i])\n",
    "        print(metric)\n",
    "        print('--------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ff039",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aa0ddf0",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b47519",
   "metadata": {},
   "source": [
    "# Max Depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33ae1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = decision_tree(3, X_train, y_train)\n",
    "y_pred, y_proba, k, clf = clf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "191501ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "metric_list = decision_metrics(X_train, y_train, y_pred)\n",
    "\n",
    "score, cm, report = metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f73d8506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.818352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true_positive_rate</td>\n",
       "      <td>0.692683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>false_positive_rate</td>\n",
       "      <td>0.103343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true_negative_rate</td>\n",
       "      <td>0.896657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false_negative_rate</td>\n",
       "      <td>0.307317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.806818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.692683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.745407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>support_pos</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>support_neg</td>\n",
       "      <td>329.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metric       score\n",
       "0             accuracy    0.818352\n",
       "1   true_positive_rate    0.692683\n",
       "2  false_positive_rate    0.103343\n",
       "3   true_negative_rate    0.896657\n",
       "4  false_negative_rate    0.307317\n",
       "5            precision    0.806818\n",
       "6               recall    0.692683\n",
       "7             f1_score    0.745407\n",
       "8          support_pos  205.000000\n",
       "9          support_neg  329.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_cm_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75253992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with Max Depth 3:\n",
      "\n",
      "The train score for the model is:\n",
      "0.8183520599250936\n",
      "--------\n",
      "Confusion Matrix:\n",
      "[[295  34]\n",
      " [ 63 142]]\n",
      "--------\n",
      "Confusion Matrix DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.82      0.90      0.86       329\\n           1       0.81      0.69      0.75       205\\n\\n    accuracy                           0.82       534\\n   macro avg       0.82      0.79      0.80       534\\nweighted avg       0.82      0.82      0.82       534\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n"
     ]
    }
   ],
   "source": [
    "list = ['The train score for the model is:', 'Confusion Matrix:', 'Confusion Matrix DataFrame:', 'Classification Report:']\n",
    "print(f'Model with Max Depth {k}:')\n",
    "print()\n",
    "for i, metric in enumerate(metric_list): # to add number to a tuple ex.: (o, seq[0]), (1, seq[1])\n",
    "    if i == 2:\n",
    "        print(list[2])\n",
    "        display(metric)\n",
    "        print('--------')\n",
    "    else:\n",
    "        print(list[i])\n",
    "        print(metric)\n",
    "        print('--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e62bae",
   "metadata": {},
   "source": [
    "# Max Depth 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef4385d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5 = decision_tree(5, X_train, y_train)\n",
    "y_pred, y_proba, k, clf = clf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abc6256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = decision_metrics(X_train, y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a898591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.818352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true_positive_rate</td>\n",
       "      <td>0.692683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>false_positive_rate</td>\n",
       "      <td>0.103343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true_negative_rate</td>\n",
       "      <td>0.896657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false_negative_rate</td>\n",
       "      <td>0.307317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.806818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.692683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.745407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>support_pos</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>support_neg</td>\n",
       "      <td>329.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metric       score\n",
       "0             accuracy    0.818352\n",
       "1   true_positive_rate    0.692683\n",
       "2  false_positive_rate    0.103343\n",
       "3   true_negative_rate    0.896657\n",
       "4  false_negative_rate    0.307317\n",
       "5            precision    0.806818\n",
       "6               recall    0.692683\n",
       "7             f1_score    0.745407\n",
       "8          support_pos  205.000000\n",
       "9          support_neg  329.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_cm_metrics(metric_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52fbb6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8408239700374532"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "748d0596",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with Max Depth 5:\n",
      "\n",
      "The train score for the model is:\n",
      "0.8408239700374532\n",
      "---------------------------------------\n",
      "Confusion Matrix:\n",
      "[[295  34]\n",
      " [ 63 142]]\n",
      "---------------------------------------\n",
      "Confusion Matrix DataFrame:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       329\n",
      "           1       0.81      0.69      0.75       205\n",
      "\n",
      "    accuracy                           0.82       534\n",
      "   macro avg       0.82      0.79      0.80       534\n",
      "weighted avg       0.82      0.82      0.82       534\n",
      "\n",
      "\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "max_list = []\n",
    "list1 = ['The train score for the model is:', 'Confusion Matrix:', 'Confusion Matrix DataFrame:', 'Classification Report:']\n",
    "print(f'Model with Max Depth {k}:')\n",
    "print()\n",
    "for i, metric in enumerate(metric_list): # to add number to a tuple ex.: (o, seq[0]), (1, seq[1])\n",
    "    max_list.append(metric)\n",
    "    if i == 2:\n",
    "        print(list1[i])\n",
    "        print(metric)\n",
    "        print()\n",
    "        print('---------------------------------------')\n",
    "\n",
    "    else:\n",
    "        print(list[i])\n",
    "        print(metric)\n",
    "        print('---------------------------------------')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "370473f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max5_list = max_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33f0f8",
   "metadata": {},
   "source": [
    "# Max Depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbe57fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = decision_tree(3, X_train, y_train)\n",
    "y_pred, y_proba, k, clf = clf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69266447",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = decision_metrics(X_train, y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac4e8635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.818352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true_positive_rate</td>\n",
       "      <td>0.692683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>false_positive_rate</td>\n",
       "      <td>0.103343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true_negative_rate</td>\n",
       "      <td>0.896657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false_negative_rate</td>\n",
       "      <td>0.307317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.806818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.692683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.745407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>support_pos</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>support_neg</td>\n",
       "      <td>329.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metric       score\n",
       "0             accuracy    0.818352\n",
       "1   true_positive_rate    0.692683\n",
       "2  false_positive_rate    0.103343\n",
       "3   true_negative_rate    0.896657\n",
       "4  false_negative_rate    0.307317\n",
       "5            precision    0.806818\n",
       "6               recall    0.692683\n",
       "7             f1_score    0.745407\n",
       "8          support_pos  205.000000\n",
       "9          support_neg  329.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_cm_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9949231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with Max Depth 3:\n",
      "\n",
      "The train score for the model is:\n",
      "0.8183520599250936\n",
      "---------------------------------------\n",
      "Confusion Matrix:\n",
      "[[295  34]\n",
      " [ 63 142]]\n",
      "---------------------------------------\n",
      "Confusion Matrix DataFrame:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       329\n",
      "           1       0.81      0.69      0.75       205\n",
      "\n",
      "    accuracy                           0.82       534\n",
      "   macro avg       0.82      0.79      0.80       534\n",
      "weighted avg       0.82      0.82      0.82       534\n",
      "\n",
      "\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "max_list = []\n",
    "list1 = ['The train score for the model is:', 'Confusion Matrix:', 'Confusion Matrix DataFrame:', 'Classification Report:']\n",
    "print(f'Model with Max Depth {k}:')\n",
    "print()\n",
    "for i, metric in enumerate(metric_list): # to add number to a tuple ex.: (o, seq[0]), (1, seq[1])\n",
    "    max_list.append(metric)\n",
    "    if i == 2:\n",
    "        print(list1[i])\n",
    "        print(metric)\n",
    "        print()\n",
    "        print('---------------------------------------')\n",
    "\n",
    "     \n",
    "    else:\n",
    "        print(list1[i])\n",
    "        print(metric)\n",
    "        print('---------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0de379b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max3_list = max_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca23800",
   "metadata": {},
   "source": [
    "# Comaprison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63f128e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       329\n",
      "           1       0.81      0.69      0.75       205\n",
      "\n",
      "    accuracy                           0.82       534\n",
      "   macro avg       0.82      0.79      0.80       534\n",
      "weighted avg       0.82      0.82      0.82       534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(max3_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9423be87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       329\n",
      "           1       0.81      0.69      0.75       205\n",
      "\n",
      "    accuracy                           0.82       534\n",
      "   macro avg       0.82      0.79      0.80       534\n",
      "weighted avg       0.82      0.82      0.82       534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(max5_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1903e0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8183520599250936"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy for max depth 3\n",
    "max3_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd4b0b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161616161616161"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab6243e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Comparison***********\n",
      "\n",
      "Model with Max Depth 3:\n",
      "\n",
      "Accuracy: 0.8183520599250936\n",
      "\n",
      "Baseline Comparison: 0.2022\n",
      "\n",
      "\n",
      "            VS\n",
      "\n",
      "\n",
      "Model with Max Depth 5:\n",
      "\n",
      "Accuracy: 0.8408239700374532\n",
      "\n",
      "Baseline Comparison: 0.2247\n",
      "     \n"
     ]
    }
   ],
   "source": [
    "print(f'''***********Comparison***********\n",
    "\n",
    "Model with Max Depth 3:\n",
    "\n",
    "Accuracy: {max3_list[0]}\n",
    "\n",
    "Baseline Comparison: {round(max3_list[0] - baseline_accuracy,4)}\n",
    "\n",
    "\n",
    "            VS\n",
    "\n",
    "\n",
    "Model with Max Depth 5:\n",
    "\n",
    "Accuracy: {max5_list[0]}\n",
    "\n",
    "Baseline Comparison: {round(max5_list[0] - baseline_accuracy,4)}\n",
    "     ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8796003",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ff1fc",
   "metadata": {},
   "source": [
    "# Validate Model with Max 3 Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc21686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52fe198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d594be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_cm_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed539e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['The validate score for the model is:', 'Confusion Matrix:', 'Confusion Matrix DataFrame:', 'Classification Report:']\n",
    "print(f'Validate Model with Max Depth {k}:')\n",
    "print()\n",
    "for i, metric in enumerate(metric_list): # to add number to a tuple ex.: (o, seq[0]), (1, seq[1])\n",
    "    if i == 2:\n",
    "        print(list[i])\n",
    "        display(metric)\n",
    "        print()\n",
    "        print('---------------------------------------')\n",
    "    elif i == 3:\n",
    "        print(list[3])\n",
    "        metric = pd.DataFrame(classification_report(y_validate, \n",
    "                                   y_val_pred, \n",
    "                                   output_dict=True)).T\n",
    "        display(pd.DataFrame(metric))\n",
    "    else:\n",
    "        print(list[i])\n",
    "        print(metric)\n",
    "        print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "max3_val_model = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292eb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max3_val_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f762a5",
   "metadata": {},
   "source": [
    "# Validate Model with Max 5 Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f1f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_val5 = decision_tree(5, X_validate, y_validate)\n",
    "y_val_pred, y_train_pred, y_proba, k, clf = clf_val5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_list = []\n",
    "\n",
    "# for i in range(1,11):\n",
    "\n",
    "#     clf_val5 = decision_tree(i, X_validate, y_validate)\n",
    "#     y_val_pred, y_val_proba, k = clf_val5\n",
    "#     print(i)\n",
    "#     print(y_val_pred.mean())\n",
    "#     val_list.append(y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8444c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = decision_metrics(X_validate, y_validate, y_val_pred)\n",
    "score, cm, cmdf, report = metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in val_list:   \n",
    "#     print(item.mean())\n",
    "#     metric = decision_metrics(X_validate, y_validate, item)\n",
    "    \n",
    "#     print(metric[0])\n",
    "#     print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bbc83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cm_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4712b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['The validate score for the model is:', 'Confusion Matrix:', 'Confusion Matrix DataFrame:', 'Classification Report:']\n",
    "print(f'Validate Model with Max Depth {k}:')\n",
    "print()\n",
    "for i, metric in enumerate(metric_list): # to add number to a tuple ex.: (o, seq[0]), (1, seq[1])\n",
    "    if i == 2:\n",
    "        print(list[i])\n",
    "        display(metric)\n",
    "        print()\n",
    "        print('---------------------------------------')\n",
    "    elif i == 3:\n",
    "        print(list[3])\n",
    "        metric = pd.DataFrame(classification_report(y_validate, \n",
    "                                   y_val_pred, \n",
    "                                   output_dict=True)).T\n",
    "        display(pd.DataFrame(metric))\n",
    "    else:\n",
    "        print(list[i])\n",
    "        print(metric)\n",
    "        print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c7f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "max5_val_model = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max5_val_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb22eb2e",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2944347",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''***********Comparison***********\n",
    "\n",
    "Validate Model with Max Depth 3:\n",
    "\n",
    "Accuracy: {max3_val_model.loc['accuracy', 'precision']}\n",
    "\n",
    "Baseline Comparison: {round(max3_val_model.loc['accuracy', 'precision'] - baseline_accuracy,4)}\n",
    "\n",
    "\n",
    "            VS\n",
    "\n",
    "\n",
    "Validate Model with Max Depth 5:\n",
    "\n",
    "Accuracy: {max5_val_model.loc['accuracy', 'precision']}\n",
    "\n",
    "Baseline Comparison: {round(max5_val_model.loc['accuracy', 'precision'] - baseline_accuracy,4)}\n",
    "     ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d44686",
   "metadata": {},
   "source": [
    "# Running a range of 1-10 and Comapring the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b26b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "train_depth = []\n",
    "train_score_list = []\n",
    "\n",
    "while i < 11:\n",
    "        \n",
    "        y_val_pred, y_train_pred, y_proba, k, clf = decision_tree(i, X_train, y_train)\n",
    "        \n",
    "        print(f'Training Model with Max Depth of: {i}')\n",
    "        # print(k)\n",
    "        \n",
    "        # print(f'Mean:{y_val_pred.mean()}')\n",
    "        # Compute score\n",
    "        \n",
    "        # print(y_val_pred.sum())\n",
    "        score = clf.score(X_train, y_train)\n",
    "        train_score_list.append(score)\n",
    "        train_depth.append(i)\n",
    "        \n",
    "        basel\n",
    "        # Print the model's accuracy and other information\n",
    "        print(f\"Model's Accuracy: {score}\")\n",
    "        print(f\"Difference between Model and Basleine Accuracy: {score - baseline_accuracy}\")\n",
    "        print('-----------------')\n",
    "\n",
    "        # Increment 'i' for the next iteration\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d31fbd",
   "metadata": {},
   "source": [
    "# Max Train Score Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb7103",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Model Max Depth {train_score_list.index(max(score_list))+1} Score: {max(train_score_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i = 1\n",
    "val_depth = []\n",
    "validate_score_list = []\n",
    "\n",
    "while i < 11:\n",
    "        \n",
    "        y_val_pred, y_train_pred, y_proba, k, clf = decision_tree(i, X_validate, y_validate)\n",
    "        \n",
    "        print(f'Training Model with Max Depth of: {i}')\n",
    "        # print(k)\n",
    "        \n",
    "        # print(f'Mean:{y_val_pred.mean()}')\n",
    "        # Compute score\n",
    "        \n",
    "        # print(y_val_pred.sum())\n",
    "        score = clf.score(X_validate, y_validate)\n",
    "        validate_score_list.append(score)\n",
    "        val_depth.append(i)\n",
    "        \n",
    "        \n",
    "        # Print the model's accuracy and other information\n",
    "        print(f\"Model's Accuracy: {score}\")\n",
    "        print('-----------------')\n",
    "\n",
    "        # Increment 'i' for the next iteration\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1cd9db",
   "metadata": {},
   "source": [
    "# Max Validate Score Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7436f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Model Max Depth {validate_score_list.index(max(score_list))+1} Score: {max(validate_score_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(train_depth, train_score_list, label='train', marker='o')\n",
    "plt.plot(val_depth, validate_score_list, label='validate', marker='o')\n",
    "plt.xlabel('max depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('how does the accuracy change with max depth on train and validate?')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b8ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
