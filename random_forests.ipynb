{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da8034cc",
   "metadata": {},
   "source": [
    "## 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14c1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydataset\n",
    "from env import get_db_url\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from prepare import prep_titanic\n",
    "from prepare import titanic_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338dd1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>baseline_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex  sibsp  parch     fare embarked  \\\n",
       "0             0         0       3    male      1      0   7.2500        S   \n",
       "1             1         1       1  female      1      0  71.2833        C   \n",
       "2             2         1       3  female      0      0   7.9250        S   \n",
       "3             3         1       1  female      1      0  53.1000        S   \n",
       "4             4         0       3    male      0      0   8.0500        S   \n",
       "\n",
       "   alone  sex_male  embarked_Q  embarked_S  baseline_prediction  \n",
       "0      0         1           0           1                    0  \n",
       "1      0         0           0           0                    0  \n",
       "2      1         0           0           1                    0  \n",
       "3      0         0           0           1                    0  \n",
       "4      1         1           0           1                    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prep_titanic()\n",
    "df['baseline_prediction'] = 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7a883d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2d23fc",
   "metadata": {},
   "source": [
    "## Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b21e00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161616161616161"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy = (df.survived == df.baseline_prediction).mean()\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e826d",
   "metadata": {},
   "source": [
    "## Cleaning the Data a little further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ae4462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fare'] = df['fare'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe8eb782",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 25, 105, 205, 405, 600]\n",
    "labels = [1, 2, 3, 4, 5]\n",
    "df['fare_bin'] = pd.cut(df['fare'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f323366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.pclass.get_dummies()\n",
    "# Assuming df is your DataFrame\n",
    "dummy_df = pd.get_dummies(df['pclass'], prefix='pclass')\n",
    "\n",
    "# Concatenate the dummy variables with the original DataFrame\n",
    "df = pd.concat([df, dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8b77cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passenger_id', 'survived', 'pclass', 'sex', 'sibsp', 'parch', 'fare',\n",
       "       'embarked', 'alone', 'sex_male', 'embarked_Q', 'embarked_S',\n",
       "       'baseline_prediction', 'fare_bin', 'pclass_1', 'pclass_2', 'pclass_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcd96f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id              int64\n",
       "survived                  int64\n",
       "pclass                    int64\n",
       "sex                      object\n",
       "sibsp                     int64\n",
       "parch                     int64\n",
       "fare                    float64\n",
       "embarked                 object\n",
       "alone                     int64\n",
       "sex_male                  uint8\n",
       "embarked_Q                uint8\n",
       "embarked_S                uint8\n",
       "baseline_prediction       int64\n",
       "fare_bin               category\n",
       "pclass_1                  uint8\n",
       "pclass_2                  uint8\n",
       "pclass_3                  uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c134be4a",
   "metadata": {},
   "source": [
    "## Train, Validate, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f76781e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, train, validate, test = titanic_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2bc84dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 534 entries, 455 to 496\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   passenger_id         534 non-null    int64   \n",
      " 1   survived             534 non-null    int64   \n",
      " 2   pclass               534 non-null    int64   \n",
      " 3   sex                  534 non-null    object  \n",
      " 4   sibsp                534 non-null    int64   \n",
      " 5   parch                534 non-null    int64   \n",
      " 6   fare                 534 non-null    float64 \n",
      " 7   embarked             534 non-null    object  \n",
      " 8   alone                534 non-null    int64   \n",
      " 9   sex_male             534 non-null    uint8   \n",
      " 10  embarked_Q           534 non-null    uint8   \n",
      " 11  embarked_S           534 non-null    uint8   \n",
      " 12  baseline_prediction  534 non-null    int64   \n",
      " 13  fare_bin             525 non-null    category\n",
      " 14  pclass_1             534 non-null    uint8   \n",
      " 15  pclass_2             534 non-null    uint8   \n",
      " 16  pclass_3             534 non-null    uint8   \n",
      "dtypes: category(1), float64(1), int64(7), object(2), uint8(6)\n",
      "memory usage: 49.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 178 entries, 176 to 837\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   passenger_id         178 non-null    int64   \n",
      " 1   survived             178 non-null    int64   \n",
      " 2   pclass               178 non-null    int64   \n",
      " 3   sex                  178 non-null    object  \n",
      " 4   sibsp                178 non-null    int64   \n",
      " 5   parch                178 non-null    int64   \n",
      " 6   fare                 178 non-null    float64 \n",
      " 7   embarked             178 non-null    object  \n",
      " 8   alone                178 non-null    int64   \n",
      " 9   sex_male             178 non-null    uint8   \n",
      " 10  embarked_Q           178 non-null    uint8   \n",
      " 11  embarked_S           178 non-null    uint8   \n",
      " 12  baseline_prediction  178 non-null    int64   \n",
      " 13  fare_bin             175 non-null    category\n",
      " 14  pclass_1             178 non-null    uint8   \n",
      " 15  pclass_2             178 non-null    uint8   \n",
      " 16  pclass_3             178 non-null    uint8   \n",
      "dtypes: category(1), float64(1), int64(7), object(2), uint8(6)\n",
      "memory usage: 16.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 561 to 53\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   passenger_id         179 non-null    int64   \n",
      " 1   survived             179 non-null    int64   \n",
      " 2   pclass               179 non-null    int64   \n",
      " 3   sex                  179 non-null    object  \n",
      " 4   sibsp                179 non-null    int64   \n",
      " 5   parch                179 non-null    int64   \n",
      " 6   fare                 179 non-null    float64 \n",
      " 7   embarked             179 non-null    object  \n",
      " 8   alone                179 non-null    int64   \n",
      " 9   sex_male             179 non-null    uint8   \n",
      " 10  embarked_Q           179 non-null    uint8   \n",
      " 11  embarked_S           179 non-null    uint8   \n",
      " 12  baseline_prediction  179 non-null    int64   \n",
      " 13  fare_bin             176 non-null    category\n",
      " 14  pclass_1             179 non-null    uint8   \n",
      " 15  pclass_2             179 non-null    uint8   \n",
      " 16  pclass_3             179 non-null    uint8   \n",
      "dtypes: category(1), float64(1), int64(7), object(2), uint8(6)\n",
      "memory usage: 16.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect\n",
    "train.info(), validate.info(), test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bcc297",
   "metadata": {},
   "source": [
    "## Removing the lesser columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d2c7359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X & y version of train/validate/test\n",
    "# where X contains the features we want to use and y is a series with just the target variable\n",
    "\n",
    "X_train = train.drop(columns=['passenger_id', 'survived', 'sex', 'fare', 'embarked', 'embarked_Q', \n",
    "        'embarked_S', 'baseline_prediction'])\n",
    "y_train = train.survived\n",
    "X_validate = validate.drop(columns=['passenger_id', 'survived', 'sex',  'fare', 'embarked', 'embarked_Q', \n",
    "        'embarked_S', 'baseline_prediction'])\n",
    "y_validate = validate.survived\n",
    "X_test = test.drop(columns=['passenger_id', 'survived', 'sex', 'fare', 'embarked', 'embarked_Q', \n",
    "        'embarked_S', 'baseline_prediction'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5fb801",
   "metadata": {},
   "source": [
    "## Columns to train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0523fe80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "['passenger_id', 'survived', 'pclass', 'sex', 'sibsp', 'parch', 'fare', 'embarked', 'alone', 'sex_male', 'embarked_Q', 'embarked_S', 'baseline_prediction', 'fare_bin', 'pclass_1', 'pclass_2', 'pclass_3'] \n",
      "_____________________________________________\n",
      "X_train:\n",
      "['pclass', 'sibsp', 'parch', 'alone', 'sex_male', 'fare_bin', 'pclass_1', 'pclass_2', 'pclass_3']\n",
      "_____________________________________________\n",
      "X_validate:\n",
      "['pclass', 'sibsp', 'parch', 'alone', 'sex_male', 'fare_bin', 'pclass_1', 'pclass_2', 'pclass_3']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Compare df columns\n",
    "\n",
    "print(f\"\"\"train:\n",
    "{train.columns.to_list()} \n",
    "_____________________________________________\n",
    "X_train:\n",
    "{X_train.columns.to_list()}\n",
    "_____________________________________________\n",
    "X_validate:\n",
    "{X_validate.columns.to_list()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a0bd1",
   "metadata": {},
   "source": [
    "## Creating A function to Fit and Transom my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d57fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(k, l, X, y):\n",
    "    \n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=l,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=k, \n",
    "                            random_state=123)\n",
    "    rf_fit = rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = rf.predict(X_train)\n",
    "    y_val_pred = rf.predict(X)\n",
    "    \n",
    "    y_proba = rf.predict_proba(X)\n",
    "    \n",
    "    \n",
    "    return y_val_pred, y_train_pred, y_proba, k, rf, rf_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8545d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred, y_train_pred, y_proba, k, rf, rf_fit = random_forest(10, 1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4e80e0",
   "metadata": {},
   "source": [
    "## 2. Evaluate your results using the model score, confusion matrix, and classification report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f13b5",
   "metadata": {},
   "source": [
    "## Creating a Functionn to produce metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "561bdf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_metrics(X, y, y_pred):\n",
    "    score = rf.score(X, y)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    cmdf = pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], \n",
    "                   columns=['Pred 0', 'Pred 1'])\n",
    "    \n",
    "    report = classification_report(y, y_pred)\n",
    "    \n",
    "    return score, cm, cmdf, report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541ab67f",
   "metadata": {},
   "source": [
    "### Extracting the variables from the function and creating a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a26acb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, cm, cmdf, report = decision_metrics(X_train, y_train, y_train_pred)\n",
    "metric_list = [score, cm, cmdf, report]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d762ce",
   "metadata": {},
   "source": [
    "### Using the list to print out clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6fb3fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with Max Depth 10:\n",
      "\n",
      "The train score for the model is:\n",
      "0.8520599250936329\n",
      "--------\n",
      "Confusion Matrix:\n",
      "[[302  27]\n",
      " [ 52 153]]\n",
      "--------\n",
      "Confusion Matrix DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>302</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>52</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred 0  Pred 1\n",
       "Actual 0     302      27\n",
       "Actual 1      52     153"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       329\n",
      "           1       0.85      0.75      0.79       205\n",
      "\n",
      "    accuracy                           0.85       534\n",
      "   macro avg       0.85      0.83      0.84       534\n",
      "weighted avg       0.85      0.85      0.85       534\n",
      "\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "list = ['The train score for the model is:', 'Confusion Matrix:', 'Confusion Matrix DataFrame:', 'Classification Report:']\n",
    "print(f'Model with Max Depth {k}:')\n",
    "print()\n",
    "for i, metric in enumerate(metric_list): # to add number to a tuple ex.: (o, seq[0]), (1, seq[1])\n",
    "    if i == 2:\n",
    "        print(list[2])\n",
    "        display(metric)\n",
    "        print('--------')\n",
    "    else:\n",
    "        print(list[i])\n",
    "        print(metric)\n",
    "        print('--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a89a3",
   "metadata": {},
   "source": [
    "## 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb96d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm_metrics(cm):    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "\n",
    "    true_positive_rate = tp/(tp + fn)\n",
    "    false_positive_rate = fp/(fp + tn)\n",
    "    true_negative_rate = tn/(tn + fp)\n",
    "    false_negative_rate = fn/(fn + tp)\n",
    "\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "    support_pos = tp + fn\n",
    "    support_neg = fp + tn\n",
    "\n",
    "    dict = {\n",
    "        'metric' : ['accuracy'\n",
    "                    ,'true_positive_rate'\n",
    "                    ,'false_positive_rate'\n",
    "                    ,'true_negative_rate'\n",
    "                    ,'false_negative_rate'\n",
    "                    ,'precision'\n",
    "                    ,'recall'\n",
    "                    ,'f1_score'\n",
    "                    ,'support_pos'\n",
    "                    ,'support_neg']\n",
    "        ,'score' : [accuracy\n",
    "                    ,true_positive_rate\n",
    "                    ,false_positive_rate\n",
    "                    ,true_negative_rate\n",
    "                    ,false_negative_rate\n",
    "                    ,precision\n",
    "                    ,recall\n",
    "                    ,f1_score\n",
    "                    ,support_pos\n",
    "                    ,support_neg]\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "075e4c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.852060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true_positive_rate</td>\n",
       "      <td>0.746341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>false_positive_rate</td>\n",
       "      <td>0.082067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true_negative_rate</td>\n",
       "      <td>0.917933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false_negative_rate</td>\n",
       "      <td>0.253659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.746341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.794805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>support_pos</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>support_neg</td>\n",
       "      <td>329.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metric       score\n",
       "0             accuracy    0.852060\n",
       "1   true_positive_rate    0.746341\n",
       "2  false_positive_rate    0.082067\n",
       "3   true_negative_rate    0.917933\n",
       "4  false_negative_rate    0.253659\n",
       "5            precision    0.850000\n",
       "6               recall    0.746341\n",
       "7             f1_score    0.794805\n",
       "8          support_pos  205.000000\n",
       "9          support_neg  329.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_cm_metrics(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2071d2a",
   "metadata": {},
   "source": [
    "## 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "488eaf1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "random_forest() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m train_score_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m11\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m         y_val_pred, y_train_pred, y_proba, k, rf_fit \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_forest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Model with Max Depth of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# print(k)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         \n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# print(f'Mean:{y_val_pred.mean()}')\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# Compute score\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         \n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# print(y_val_pred.sum())\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: random_forest() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "j = 1\n",
    "train_depth = []\n",
    "train_score_list = []\n",
    "\n",
    "while i < 11:\n",
    "        \n",
    "        y_val_pred, y_train_pred, y_proba, k, rf_fit = random_forest(i, j, X_train, y_train)\n",
    "        \n",
    "        print(f'Training Model with Max Depth of: {i}')\n",
    "        # print(k)\n",
    "        \n",
    "        # print(f'Mean:{y_val_pred.mean()}')\n",
    "        # Compute score\n",
    "        \n",
    "        # print(y_val_pred.sum())\n",
    "        score = clf.score(X_train, y_train)\n",
    "        train_score_list.append(score)\n",
    "        train_depth.append(i)\n",
    "        \n",
    "        basel\n",
    "        # Print the model's accuracy and other information\n",
    "        print(f\"Model's Accuracy: {score}\")\n",
    "        print(f\"Difference between Model and Basleine Accuracy: {score - baseline_accuracy}\")\n",
    "        print('-----------------')\n",
    "\n",
    "        # Increment 'i' for the next iteration\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d3bb68",
   "metadata": {},
   "source": [
    "## 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09faa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
